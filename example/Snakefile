"""
Generates kmers for samples
"""

configfile: "config_kmers.yaml"

ruleorder: count_kmers > filter_kmers

target_kmers = [21]

rule all:
    input:
        expand("output/{sample}_k{thisk}.kmers", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_CAGT_k{thisk}.kmers", sample=config["sample"], thisk=target_kmers),
        "output_snp/Physalia_merged.beagle.gz",
        "output_snp/pca_output.mafs"

rule decompress_reads:
    input:
        reads = lambda wildcards: [f"{config['base_read_dir']}{x}" for x in config["sample"][wildcards.sample]["reads"]]
    output:
        R1 = temp("reads/{sample}_all_R1.fastq"),
        R2 = temp("reads/{sample}_all_R2.fastq")
    group:
        lambda wildcards: f"sample_{wildcards.sample}"
    params:
        sample = lambda wildcards: wildcards.sample,
        max_lines = 400000000
    shell:
        """
        # Concatenate reads
        set +o pipefail  # Disable strict mode so that pipe to head doesn't die
        zcat {input.reads}/*R1*.fastq.gz | head -n {params.max_lines} > {output.R1}
        zcat {input.reads}/*R2*.fastq.gz | head -n {params.max_lines} > {output.R2}
        """
        
        
rule trim_reads:
    input:
        R1 = "reads/{sample}_all_R1.fastq",
        R2 = "reads/{sample}_all_R2.fastq"
    output:
        R1_paired   = temp("reads/{sample}_trimmed_paired_R1.fastq"),
        R1_unpaired = temp("reads/{sample}_trimmed_unpaired_R1.fastq"),
        R2_paired   = temp("reads/{sample}_trimmed_paired_R2.fastq"),
        R2_unpaired = temp("reads/{sample}_trimmed_unpaired_R2.fastq")
    group:
        lambda wildcards: f"sample_{wildcards.sample}"
    params:
        sample = lambda wildcards: wildcards.sample
    threads: workflow.cores
    log: "logs/trimmomatic/trimmomatic_{sample}.log"
    shell:
        """
        
        # Multiple operations are combined into a single rule here to minimize the number of files on disk at any point in time.
        
        

        # Trim reads
        echo ">PrefixPE/1\nTACACTCTTTCCCTACACGACGCTCTTCCGATCT\n>PrefixPE/2\nGTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT" > TruSeq3-PE.fa
        trimmomatic PE \
          -threads {threads} \
          {input.R1} \
          {input.R2} \
          {output.R1_paired} \
          {output.R1_unpaired} \
          {output.R2_paired} \
          {output.R2_unpaired} \
          ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:True LEADING:15 TRAILING:15 MINLEN:50 2> {log}
        """

rule count_reads:
    input:
        R1 = "reads/{sample}_all_R1.fastq",
        R2 = "reads/{sample}_all_R2.fastq",
        R1_paired   = "reads/{sample}_trimmed_paired_R1.fastq",
        R1_unpaired = "reads/{sample}_trimmed_unpaired_R1.fastq",
        R2_paired   = "reads/{sample}_trimmed_paired_R2.fastq",
        R2_unpaired = "reads/{sample}_trimmed_unpaired_R2.fastq"
    output:
        read_count = "output/{sample}.count"
    group:
        lambda wildcards: f"sample_{wildcards.sample}"
    params:
        sample = lambda wildcards: wildcards.sample,
    shell:
        """
        # Count reads
        sum=0
        num_lines_raw=$(cat {input.R1} | wc -l)
        num_reads_raw=$(($num_lines_raw / 4))
        num_nucleotides_raw=$(cat {input.R1} {input.R2} | awk '{{if(NR%4==2) sum+=length($0)}} END {{print sum}}' )

        sum=0
        num_lines_trimmed=$(cat {intput.R1_paired} | wc -l)
        num_reads_trimmed=$(($num_lines_trimmed / 4))
        num_nucleotides_trimmed=$(cat {input.R1_paired} {input.R2_paired} | awk '{{if(NR%4==2) sum+=length($0)}} END {{print sum}}' )

        sum=0
        num_lines_unpaired_trimmed=$(cat {input.R1_unpaired} {input.R2_unpaired} | wc -l)
        num_reads_unpaired_trimmed=$(($num_lines_unpaired_trimmed / 4))
        num_nucleotides_unpaired_trimmed=$(cat {input.R1_unpaired} {input.R2_unpaired} | awk '{{if(NR%4==2) sum+=length($0)}} END {{print sum}}' )

        echo "reads_pairs_raw\t$num_reads_raw" > {output.read_count}
        echo "nucleotides_raw\t$num_nucleotides_raw" >> {output.read_count}
        echo "reads_pairs_trimmed\t$num_reads_trimmed" >> {output.read_count}
        echo "nucleotides_trimmed\t$num_nucleotides_trimmed" >> {output.read_count}
        echo "reads_unpaired_trimmed\t$num_reads_unpaired_trimmed" >> {output.read_count}
        echo "nucleotides_unpaired_trimmed\t$num_nucleotides_unpaired_trimmed" >> {output.read_count}
        """


rule count_kmers:
    input:
        R1_paired   = "reads/{sample}_trimmed_paired_R1.fastq",
        R2_paired   = "reads/{sample}_trimmed_paired_R2.fastq"
    output:
        kmers = "output/{sample}_k{thisk}.kmers",
        jf = temporary("output/{sample}_k{thisk}.jf")
    group:
        lambda wildcards: f"sample_{wildcards.sample}"
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
    threads: workflow.cores
    log: "logs/jellyfish/jellyfish_{sample}_k{thisk}.log"
    shell:
        """
        jellyfish count -C -m {params.thisk} -s 1000000000 -t {threads} \
          -o {output.jf} \
          {input.R1_paired} {input.R2_paired} \
          2> {log}

        jellyfish dump -c -L 2 -o {output.kmers} {output.jf} 
        """

rule filter_kmers:
    input:
        kmers = "output/{sample}_k{thisk}.kmers"
    output:
        kmers = "output/{sample}_CAGT_k{thisk}.kmers"
    shell:
        """
        grep -P "^CAGT" {input.kmers} > {output.kmers}
        """

rule run_snpquest:
    input:
        expand("output/{sample}_CAGT_k{thisk}.kmers", sample = config["sample"], thisk = target_kmers)
    output:
        expand("output_snp/{sample}_CAGT_k{thisk}.vcf", sample = config["sample"], thisk = target_kmers),
        "output_snp/Physalia.pseudogenome.fasta"
    shell:
        "../target/release/snpquest --outdir output_snp/ --freq-min 1.0 --run-name Physalia --prefix 'CAGT' {input}"

rule bgzip_vcf:
    input:
        "output_snp/{sample}_CAGT_k{thisk}.vcf"
    output:
        "output_snp/{sample}_CAGT_k{thisk}.vcf.gz"
    shell:
        "bgzip {input}"

rule index_vcf:
    input:
        "output_snp/{sample}_CAGT_k{thisk}.vcf.gz"
    output:
        "output_snp/{sample}_CAGT_k{thisk}.vcf.gz.tbi"
    shell:
        "tabix -p vcf {input}"

rule index_fasta:
    input:
        "output_snp/Physalia.pseudogenome.fasta"
    output:
        "output_snp/Physalia.pseudogenome.fasta.fai"
    shell:
        "samtools faidx {input}"

rule merge_vcf:
    input:
        tbi = expand("output_snp/{sample}_CAGT_k{thisk}.vcf.gz.tbi", sample = config["sample"], thisk = target_kmers),
        vcf = expand("output_snp/{sample}_CAGT_k{thisk}.vcf.gz", sample = config["sample"], thisk = target_kmers)
    output:
        "output_snp/Physalia_merged.vcf"
    shell:
        "bcftools merge {input.vcf} -o {output}"

rule convert_to_beagle:
    input:
        "output_snp/Physalia_merged.vcf"
    output:
        "output_snp/Physalia_merged.beagle.gz"
    shell:
        "bcftools view -G -O z {input} > {output}"

rule run_angsd:
    input:
        "output_snp/Physalia_merged.beagle.gz",
        "output_snp/Physalia.pseudogenome.fasta.fai"
    output:
        "output_snp/pca_output.mafs"
    shell:
        "angsd -beagle {input[0]} -doCov 1 -doMajorMinor 1 -doMaf 1 -out pca_output -fai {input[1]}"